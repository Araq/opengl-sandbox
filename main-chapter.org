#+TITLE: Implementation




* TODO
** TODO glm port for the typechecker
** TODO typed and untyped macros
** TODO two pass macro, type injection
** TODO gathering used types and procedures
** TODO type normalization
** TODO translation from Nim IR to GLSL
** TODO identifier transformation
*** underscore separator
*** collision prevention with glsl keywords
** TODO AST pattern matching
** TODO matching the for construct

** TODO mention the reason to restrict the vertex type to tuple
** TODO explain strided view

** TODO symbol disambiguation (resolve symbol collisions)

** TODO mention support for gdb pretty printers (lot of time wasted getting it to work).
** TODO mention problems with AST. For loop is eleminated, maybe?
* log

It is not suitable to use the persistently mapped buffer to render
from a loop.  The buffer content will not be synced on each draw call,
leaving several draws with the identical uniform data.  This leads to
the situation that all object that should be drawn at different
locations end to be rendered all at the exact same location.


it is horrible for me to write this document, because I am always
procrastinating the whole day long and then in the evening I have
don't nothing and still extremely exhausted. Then I won't go to bed
because I feel I did not accomplish enough and then the next day I
already start being exhausted without even having written anything.

** instance array

A special kind of loop that initializes some local variables and then
renders from those local variables.  But in reality it creates an
attribute buffer for all used local variables and renders everything
is just one draw call.

Here is some pseudo code, but this loop in a loop should be compiled
with automatic data serialization to a single draw call.

#+BEGIN_SRC nim

for mesh in mymeshes:
  let numInstances = 10
  let a = 123
  let #[ ... some locals ... ]#
  for instance in mesh.instanciate(numInstances):
    let b = 321
    let #[ ... some other locals ... ]#
    mesh.render (v, gl) do:
      result.color.r = a
      result.color.g = b

#+END_SRC

* base example

# Why I chose an example for explanation?
To my knowledge it is easiest to understand a new topic with a
concrete example.  Therefore I would like to explain the internals of
the compiler with an example.  The example that I choose should be an
example that is easy to understand in terms of complexity, could be
part of a real rendering program, should cover many features that I want
to support and last but not least the example should give the reader
an impression of what is this approach is able to accomplish.

# What is the example about?
In listing ref:base-example I show an example that I made executable
over the course of this mater thesis.  It renders a mesh with texture
mapping and vertex-normals.  In the vertex shader the lighting is
calculated by a simple loop that iterates over all light sources.

Features this example covers:

  * uniforms
  * attributes
  * non-builtin types (Light)
  * for loop (iterator)

#+caption: Base Example label:base-example
#+BEGIN_SRC nim
import glm, macros

macro render(args: varargs[untyped]): untyped =
  for arg in args:
    echo arg.treeRepr

type
  Mesh[T] = object
  Framebuffer[T] = object
  Texture2D = object

type
  MyFragmentType = object
    color: Vec4f

  MyVertexType = object
    position_os: Vec4f
    normal_os: Vec4f
    texCoord: Vec2f

  Light = object
    position_ws : Vec4f
    color : Vec4f

  MyMesh        = Mesh[MyVertexType]
  MyFramebuffer = Framebuffer[MyFragmentType]

var myTexture: Texture2D
var mesh: MyMesh
var framebuffer: MyFramebuffer
var mvp: Mat4f

var M,V,P: Mat4f
var lights: array[10,Light]

framebuffer.render(mesh) do (v, gl):
  gl.Position     = (P * V * M) * v.position_os
  let position_cs = V*M*v.position_os
  let normal_cs   = inverse(transpose(V*M)) * v.normal_os
  var lighting: Vec4f

  ## rasterize

  for light in lights:
    let light_position_cs = V * light.position_ws
    let light_direction_cs = light_position_cs-position_cs
    let light_intensity = dot(light_direction_cs, normal_cs)
    lighting += light_intensity * light.color

  let textureSample = texture(myTexture, v.texCoord)
  result.color = textureSample * lighting

#+END_SRC

** Type Checking Phase

The symbol ~render~ is the macro and the entire block including the
symbol ~framebuffer~ until the end of the macro is the argument of the
macro.  For now to keep the complexity low, I just assume that
every symbol inside of the AST can be resolved by the Nim type
checker.  There is a trick that I do to achieve this explained in more
detail in [[sec:two-layer-macro]].  The typechecked ast is very verbose in
its tree representation, but for the last two lines the AST looks like
the following.

#+BEGIN_SRC
    LetSection
      IdentDefs
        Sym "textureSample"
        Empty
        Call
          Sym "texture"
          Sym "myTexture"
          DotExpr
            Sym "v"
            Sym "texCoord"
          FloatLit 0.0
    Asgn
      DotExpr
        Sym "result"
        Sym "color"
      Infix
        Sym "*"
        Sym "textureSample"
        Sym "lighting"
#+END_SRC

# the AST structure
Each node is tagged with a node kind, for example ~LetSection~,
~Call~, ~DotExpression~, ~Sym~, etc, and each node has an arbitrary
amount of children. Some nodes have string values like symbols and
string literals. Also Literals also contain their value.

# additional information that is in the AST
Type information can not only be queried from symbol nodes, but also
from all expressions.  For example when ~getTypeInst~ is called on the
~Infix~ node in the excerpt above, it will return the type ast of
exactly that node.  Types are represented in AST form as well.  For
example the type ~Vec4f~ will be represented after normalization as
~Vec[4, float32]~.  Symbols also have a symbol tag (not visible
in the tree) that specifies what kind of symbol it is.  This tag can
be used to identify if a symbol is a type, a function, a variables, a
constant etc.  From type and function symbols it is possible to jump
to the AST of the implementation.

# TODO reference the type normalization section

From all the information that this AST provides, it is possible to
generate everything necessary to run that code on the GPU.

** vertex fragment shader separation

At the time of writing this, the magic comment ~## rasterize~ defines
the split point of vertex and fragment shader.  Everything before that
comment is defined to be part of the vertex shader, everything behind
it will be compiled into the fragment shader.

I don't necessarily like this magic comment, and I think eventually it
should go away. But the advantages of this magic comment are that it is
easy to understand and very easy to implement.  it serves its
purpose very well to split between vertex shader and fragment shader.

** Extraction of Meta Information

From all the information the AST provides several lists are extracted
that will be used for code generation

 * Uniforms :: Variable symbols used in the body automatically become
               /uniform/ variables, when their declaration lies outside of the
               body.  The values of these symbols need to
               be serialized and passed as /uniform/ to the /program/.

 * Attributes :: Every member of the vertex object automatically
                 becomes an /attribute/, when it is used in the
                 /body/.  A /program/ that does not access the vertex
                 object will not have attributes.

 * Types :: Locals variables and /uniforms/ may have a type that is
            not already defined in GLSL.  These types will need a type
            declaration so that they can be used in GLSL.

 * Procedures :: Similar to /types/ used procedures that are not built
                 into GLSL need to bo compiled ot GLSL as well.  To
                 compile procedures the procedure body needs to be
                 scanned recursively for more /uniforms/, /types/
                 and /procedures/.

 * Varyings :: Symbols that are declared in the vertex shader, but are
               accessed from the fragment shader are symbols that need
               to be rasterized as varying.

** passing uniforms

# how passing uniforms generally works and what should be taken care of.

When the shader program uses a symbol that is not locally defined
within the shader block, it has to be a passed to the shader as a
uniform.  It is known at compile time what symbols are used, how many
symbols are used, and what their type is, but it is not known at
compile time what value they have.  A matrix that is used could be a
new matrix uniform on each draw call, and a texture could be an
entirely different texture object on each draw call.  This needs to be
taken care of.  Generally I distinguish between two kinds of uniforms,
the plain old data uniforms, like matrices, vectors and scalars. And
texture uniforms that are represented by a handle on the client.  All
uniforms that are just plain old data can simply be passed to the
shader program in one block of binary data, the uniform buffer.  For
textures though, this does not work.  Putting the texture handle into
the uniform buffer does not work.  In OpenGL textures are not passed
directly to the /shader/.  Internally OpenGL has a list of active
textures, the active textures list.  A texture needs to be bound to a
spot in this active texture list first.  Then the program that uses a
textures needs to know the index of the texture in the active texture
list.  This can be done for example by passing an integer to the
/uniform/ variable.  I personally think that this list of active
textures is an unnecessary indirection that causes way too much
confusion.  So I found a way that the programmer does not need to
worry about it anymore.  He will be able to use texture variables in
the /shader/ directly, as if this indirection would not exist.

[[./images/active-texture.png]]

# how I pass my uniforms to the shader
So first of all, I split all the used uniform symbols into two
different kinds of uniforms, the /texture/ uniforms, and the
/non-texture/ uniforms. All /non-texture/ uniforms are automatically
joined into a single uniform buffer, which is then passed to the
program in one batch.

# TODO reference the struggles of serializing uniforms.

For textures I have a slightly different approach.  Since I know all
symbols statically, I assign each texture symbol to one position in
the active texture array at compile time.  So for example the first
used texture symbol will use ~GL_TEXTIRE0~ the second one will use
~GL_TEXTURE1~ etc.  This also won't change anymore at run-time, but
the actual value (handle) of the texture symbol can change at any,
even between every draw call.  Therefore I bind every used texture
/symbol/ to its active texture unit every time before the draw call.
Since all used texture units are in a consecutive array they can be
set in one batch with ~glBindImageTextures~.

It will not be necessary any more to change the active texture unit
with a call like ~glUniform1i~ after initial setup.  And yet every
texture variables is usable from the /shader/, no matter how often the
value changes.

#+BEGIN_SRC glsl
// here I start at 0, but I could start at any other index.
layout(binding=0) uniform sampler2D reflection;
layout(binding=1) uniform sampler2DShadow color;
layout(binding=2) uniform samplerCube skybox;
#+END_SRC

#+BEGIN_SRC nim
var handles = [reflection.handle, color.hanle, skybox.handle]
glBindTextures(0, GLsizei(handles.len), handles[0].addr)
#+END_SRC

# possible optimization

I would like to discuss a theoretical optimization.  When there is a
single constant texture used in a majority of the /shaders/, this
texture can be bound permanently to a texture unit.  So there will be
two different ranges in the active textures list.  At the beginning
there will be the array of constant active textures that will never be
unbound, and after that there will be all the be the texture unites
that will be rebound on every draw call. Every program would need to
know at initialization about all global textures, because otherwise it
would override the global texture units with it's own used textures.
For some cases this would prevent binding textures before the draw
call at all.

#+BEGIN_SRC glsl
  // here are all used texture uniforms from the statically reserved
  // active textures
  layout(binding=0) uniform sampler2DRect fontAtlas;

  // the used active textures are now of course shifted by the total
  // amount of statically reserved active textures.  For the purpose of
  // this example I assume that there is another statically reserved
  // active texture in the program, that is not used in this shader. So
  // all used texture uniforms are shifted by 2 in the index.
  layout(binding=2) uniform sampler2D reflection;
  layout(binding=3) uniform sampler2DShadow color;
  layout(binding=4) uniform samplerCube skybox;
#+END_SRC

#+BEGIN_SRC nim
var handles = [reflection.handle, color.hanle, skybox.handle]
glBindTextures(2, GLsizei(handles.len), handles[0].addr)
#+END_SRC

The advantage here is that statically reserved active texture units
don't need any OpenGL state change at all.  But I have no measurement
at all on how much performance gain there is nor how much performance
gain might even be possible.

The disadvantage here is mostly that the programmer needs to take
active care of these statically reserved active texture units.  He
needs to be aware on how many there are.  The limits are at least 48 by
the standard, and on my computer there cannot be more than 192
combined texture image units.  Also all texture unit reservation needs
to take place before the first shader program is compiled, because
otherwise the offset for the dynamically bound active textures won't
be correct anymore.

Because of the disadvantages and no guarantee for a performance gain,
this has not been implemented yet.  But this technique will be picked
up again, if binding textures turns out to be expensive.


** Translating Symbols to glsl

Translating symbols to glsl could be done just by writing the name of
the symbol to glsl. I could rename all symbols to generic names such
as ~sym1~, ~sym2~, ~sym3~, ... but this make the generated code very
hard to read.  And I would really like to be able to read the
generated code, just to verify that it is correct.  Whenever something
doesn't work and I need to check manually what went wrong in the code
generation process, it helps a lot when the generated code is readable
and maintains the names of the original symbols.  Eventually if
everything works 100% correct, it does not matter how the generated
code looks like, but at the current state of development I can't
guarantee that.

# underscores
Nim has a very weird rule for identifier equality.  First of all it is
case insensitive (except for the first character), and it ignores
underscores in names.  so ~foo_bar~ and ~fooBar~ are equal according
to Nim identifier comparison, but ~foobar~ and ~Foobar~ are not.  I
don't necessarily like this but I can use it to my advantage.  First
of all I can remove all underscores from identifiers without creating
name clashes from Nim symbols.  Then the underscore becomes free for
me to use as a separator for symbol disambiguation. For example I can
generate ~in_foobar~ and it cannot clash with a symbol from the ast,
because if ~in_foobar~ would be used inside of the body, it would be
translated to ~infoobar~.

# resolving keyword conflicts
Nim allows symbols to be named like keywords of glsl. This is simply
resolved with a list of all glsl keywords.  Whenever a symbol name is
a keyword in glsl, I will know that by looking in that list, and I
will append a post-fix to the generated symbol in glsl for
disambiguation.

** Translating Types to glsl

# translating simple types to glsl
Most types that are used in the code block should be built-in types of
glsl, just the correct mapping of the types should be done.  For
example the Nim type ~int32~ will be translated to ~int~ and ~float32~
will be translated to ~float~.  A bit more complex are the
vec-types.  For example the type ~Vec4f~ is an alias to
~Vec4[float32]~ which is also just an alias to ~Vec[4,float32]~.  For
this alias resolution I implemented a ~normalizeType~ function that
resolves all alias types to their non alias name.  In this case all of
the three representations would be mapped to ~Vec[4,float32]~.  The
generic Vec types are easy to map to the built-in types of glsl.  For
example ~Vec[4,float32]~ is translated to ~vec4~ and ~Vec[2, int32]~
is translated to ~ivec2~, etc.

# translating used defined types to glsl

For user defined types, the type definition needs to be translated to
glsl as well.  In the given example that would be the type ~Light~
that is used by iterating the lights array.  A simple check of that
symbol is a built-in types should verify that this type is a user
defined type.  With ~getImpl~ on the ~Light~ type symbol I can get to
the implementation and use it to translate it to GLSL.  Here is an
example how the translation of that type looks like.

#+caption: Light Type Definition in Nim
#+BEGIN_SRC nim
type
  Light = object
    position_ws : Vec4f
    color : Vec4f
#+END_SRC

#+caption: Light Type AST from getImpl
#+BEGIN_SRC
ObjectTy
  Empty
  Empty
  RecList
    IdentDefs
      Sym "position_ws"
      Sym "Vec4f"
      Empty
    IdentDefs
      Sym "color"
      Sym "Vec4f"
      Empty
#+END_SRC

#+caption: Light Type in glsl
#+BEGIN_SRC glsl
struct Light {
  vec4 positionws;
  vec4 color;
};
#+END_SRC

Of course types that are used as members here need to be translated to
GLSL as well, when they are not already built-in.  In this example
this is not necessary though, because ~vec4~ is a built-in type.

# translating procedures to glsl

All used procedures can be found simply by scanning thorough the
statements of the body. Whenever a call appears in the AST, the first
argument of that node is the procedure symbol. For each symbol one of
the following steps needs to be done.

# TODO thin can also be a type constructor
 * built-in :: The function symbol is a function that is already built
               into glsl. Nothing needs to be done.
 * already collected :: It is not the first appearance of this
      function symbol. Nothing needs to be done.
 * new function symbol :: This is the first appearance of the function
      symbol.  Just append this symbol to the list of functions that
      need to be compiled to glsl.

All function symbols are compiled to glsl like all other functions,
but they might also use functions which on their own also need to be
compiled to glsl.  This process is recursive and can create an
arbitrary amount of dependencies.

# translating generics to glsl

A good very good help from the Nim compiler is, it does the generic
instanciation for me. So when for example the function foo has one
generic argument, and I ask for the implementation, I will get a
different one for `foo(12'f32)`, than I would get for
`foo(12'f64)`. Also the function symbol will be a different one, with
the same name though. So when I use both versions of foo, the setup
above already generates both versions for me.

** working on the Framebuffer type

a frambeffure needs the following attributes

  * size :: each attachment needs to have this size
  * depth attachment :: can be DepthTexture or a DepthRenderbuffer
  * stencil attachment :: I don't know what it can be
  * color attachments :: these can be an arbitrary amount of
       attachments.

Each attachments needs to have the following information:
  * name :: each attachment needs to have a name
  * glsl type :: the type in glsl for the output variable
  * internal format :: how is it stored internally. float, normalized
       int, or something else. Also for the depth it specifies the
       precision
  * texture type :: what kind of texture is the color attachment?
                    Texture2D, Texture2DRect, Texture2DShadow, ...

Open questions

 * ownership :: who owns the attachments? Are the attachments created
                with the Framebuffer and die with it, or is the
                lifetime of the Attachment independent of the
                Framebuffer?

 * compile or run time :: Which information needs to be statically
      known at compile time for code generation. Which information
      needs to be statically known? Which information is best
      specified at runtime?


a Framebuffer as a depth




** the two layer macro
   <<sec:two-layer-macro>>

# how the nim typechecker works, and why I create the outer macro.
The typechecker in Nim can only check types of the Nim programming
language with semantics of the Nim programming language.  The type
checking algorithm itself is not script-able.  Therefore I need to map
glsl semantics somehow to the Nim programming language.  Most glsl
types map nicely to the types defined in the glm library.  Then the
glsl part needs to have some context for the typechecker that I inject
with a two layer macro (where the full will you talk about it).

From here on I assume that all types of glsl also work flawlessly in
Nim.  For more details on how this works see the glsl section.

In order for the typecheck to be able to resolve all symbols correctly
I use the pattern with a two layer macro.  The outer macro takes a
non-type-checked AST, and then generates an AST that is capabale to be
fully type-checked.  The then generated AST is a statment to a typed
macro.  With this pattern it is possible to introduce symbols that
only exist in the embedded DSL.  In the listings ref:two-layer-macro-a
and ref:two-layer-macro-a you see how I introduce the symbol ~gl~ with
this pattern.

#+caption: Two Layer Macro A label:two-layer-macro-a
#+BEGIN_SRC nim
framebuffer.render(mesh) do (v):
  gl.Position     = (P * V * M) * v.position_os
  #[...]#
#+END_SRC

This will be transformed into the following statement:

#+caption: Two Layer Macro B label:two-layer-macro-b
#+BEGIN_SRC nim
block:  # A code block to create a new variable scope.
  gl: var GlShaderContext {.inject.} # inject to prevent symbol hiding hygienic
  render_inner(framebuffer, mesh) do (v: MyVertexType) -> MyFragmentType:
    gl.Position     = (P * V * M) * v.position_os
    #[ ... ]#
#+END_SRC

Now the type checker can resolve all symbols from the inner body of
this macro.  The typechecked AST is reprinted here again in nim representation.

#+BEGIN_EXAMPLE

do (v: MyVertexType; gl: var GlShaderContext) -> MyFragmentType:
  gl.Position = P * V * M * v.position_os
  let position_cs = V * M * v.position_os
  let normal_cs = inverse(transpose(V * M)) * v.normal_os
  var lighting: Vec4f
  block tmp346054:
      var light: Light
      var i = 0
      if i <= 9:
        block tmp346055:
            while true:
              light = lights[i]
              let light_position_cs = V * light.position_ws
              let light_direction_cs = light_position_cs - position_cs
              let light_intensity = dot(light_direction_cs, normal_cs)
              lighting += light_intensity * light.color
              if 9 <= i:
                break tmp346055
              inc(i, 1)
  let textureSample = texture(myTexture, v.texCoord, 0.0)
  result.color = textureSample * lighting

#+END_EXAMPLE

For representation alone it is not obvious that it is now a tree
of resolved symbols, but the full tree would be too large to be shown
here. This is only the last last line printed in tree representation:

#+BEGIN_EXAMPLE
  Asgn
    DotExpr
      Sym "result"
      Sym "color"
    Infix
      Sym "*"
      Sym "textureSample"
      Sym "lighting"

#+END_EXAMPLE

I don't know what to do to prevent that the for loop becomes a while
loop.  Should I filter for this while loop and translate it back to a
for loop in glsl? Or should I just translate into a while loop and
hope the glsl compiler will be able to unroll it anyway?  Glsl
performance might really suffer from dynamically sized arrays, but
this should really be tested,  I did not test it at all yet.

** preventing the `iterator items` expansion, or matching against it?

The metainformation that is important for the next steps are the
following:

 * split vertex and fragment shader parts
 * extract all used uniforms
 * extract all used attributes and in witch shader they are used
 * extract identifiers that are used as varyings.
 * used types (non glsl types)

*** Extract Vertex and Fragment Shader

**** TODO introduce name for the argument of the macro (the AST).

# How do I get metainformation.
# What uniforms are used
# What attributes are used
# how do I translate identifiers

** preventing the `iterator items` expansion, or matching against it?

From here on the Nim code should be translated directly into
GLSL. Even though I haven't talked at all about the shader stage
separation at all, and this is important.

* symbol table

| symbol             | kind         | glsl repr        | type                    |
|--------------------+--------------+------------------+-------------------------|
| inversse           | BuiltinProc  | inversse         |                         |
| transpose          | BuiltinProc  | transpose        |                         |
| texture            | BuiltinProc  | texture          |                         |
| dot                | BuiltinProc  | dot              |                         |
| vec4f              | BuiltinProc  | vec4             |                         |
| M                  | Uniform      | M                | Mat[4,float32]          |
| V                  | Uniform      | V                | Mat[4,float32]          |
| P                  | Uniform      | P                | Mat[4,float32]          |
| lights             | Uniform      | lights           | array[3,Light]          |
| v.position_os      | Attribute    | v_positionos     | Vec[4,float32]          |
| v.normal_os        | Attribute    | v_normalos       | Vec[4,float32]          |
| v.texCoord         | Attribute    | v_texCoord       | Vec[2,float32]          |
| result.color       | Result       | result_color     | Vec[4,float32]          |
| Vec4f              | Type         | vec4             | Vec[4,float32]          |
| Mat4f              | Type         | mat4             | Mat[4,float32]          |
| float32            | Type         | float            | float32                 |
| light              | LoopIt       | ???              | ???                     |
| position_ws        | Member       | positionws       | Light -> Vec[4,float32] |
| color              | Member       | color            | Light -> Vec[4,float32] |
| position_cs        | LocalVar     | positioncs       | Vec[4,float32]          |
| normal_cs          | LocalVar     | normalcs         | Vec[4,float32]          |
| lighting           | LocalVar     | lighting         | Vec[4,float32]          |
| light_position_cs  | LocalVar     | lightpositioncs  | Vec[4,float32]          |
| light_direction_cs | LocalVar     | lightdirectioncs | Vec[4,float32]          |
| light_intensity    | LocalVar     | lightintensity   | float32                 |
| textureSample      | LocalVar     | textureSample    | Vec[4,float32]          |
| t1                 | Intermediate | temp_1           | Mat[4,float32]          |
| t2                 | Intermediate | temp_2           | Mat[4,float32]          |
| t3                 | Intermediate | temp_3           | Mat[4,float32]          |
| t4                 | Intermediate | temp_4           | float32                 |
| t5                 | Intermediate | temp_5           | Vec[4,float32]          |
| t6                 | Intermediate | temp_6           | Vec[4,float32]          |
| t7                 | Intermediate | temp_7           | Vec[4,float32]          |

* intermediate representation

#+BEGIN_SRC

(Block
  (Asgn `gl.Position` (Mult `P` `V` `M` `v.position_os`))
  (Asgn `position_cs` (Mult `V` `M` `v.position_os`))
  (Asgn `t1` (Mult `V` `M`))
  (Asgn `t2` (Call `transpose` `t1`))
  (Asgn `t3` (Call `inverse` `t2`))
  (Asgn `normal_cs` (Mult `t3` `v.normal_os`))
  (Asgn `lighting`  (Call `vec4f` 0))
  (Loop `light` `lights`
    (Asgn `t4` (Dot `light` `position_ws`))
    (Asgn `light_position_cs` (Mult `V` `t4`))
    (Asgn `t5` (Neg `position_cs`))
    (Asgn `light_direction_cs` (Add `t5` `light_position_cs`))
    (Asgn `light_intensity`  (Call `dot` `light_direction_cs` `normal_cs`))
    (Asgn `t6` (Dot `light` `color`))
    (Asgn `t7` (Mult `light_intensity` `t6`))
    (Asgn `lighting` (Add `lighting` `t7`))
  )
  (Asgn `textureSample` (Call `texture` `myTexture` `v.texCoord`))
  (Asgn `result.color` (Mult `texturesample` `lighting`))
)

#+END_SRC


all symbols in the loop body need to be in a group, because a variable
in the loop body can't be passed down to the fragment shader.

* all <= relations

| `gl.Position`        | `P`                  |
| `gl.Position`        | `V`                  |
| `gl.Position`        | `M`                  |
| `gl.Position`        | `v.position_os`      |
| `position_cs`        | `V`                  |
| `position_cs`        | `M`                  |
| `position_cs`        | `v.position_os`      |
| `t1`                 | `V`                  |
| `t2`                 | `M`                  |
| `t2`                 | `t1`                 |
| `t3`                 | `t2`                 |
| `normal_cs`          | `t3`                 |
| `normal_cs`          | `v.normal_os`        |
| `t4`                 | `light`              |
| `t4`                 | `light`              |
| `light_position_cs`  | `V`                  |
| `light_position_cs`  | `t4`                 |
| `t5`                 | `position_cs`        |
| `light_direction_cs` | `t5`                 |
| `light_direction_cs` | `light_position_cs`  |
| `light_intensity`    | `light_direction_cs` |
| `light_intensity`    | `normal_cs`          |
| `t6`                 | `light`              |
| `t6`                 | `color`              |
| `t7`                 | `light_intensity`    |
| `t7`                 | `t6`                 |
| `lighting`           | `lighting`           |
| `lighting`           | `t7`                 |
| `textureSample`      | `myTexture`          |
| `textureSample`      | `v.texCoord`         |
| `result.color`       | `texturesample`      |
| `result.color`       | `lighting`           |


#+BEGIN_SRC nim

type
  IRNodeKinds = enum
    irBlock
    irAsgn
    irDot
    irMult
    irAdd
    irNeg
    irCall
    irDecl
    irLoop

#+END_SRC

* generated shader source

This is how the generated shader source could/should look like. This
code is hand translated, so it is not guaranteed that the final
compiler will generate exactly this shader code, but at the current
state of development it looks like this could be done.

** TODO talk about shader stage separation

#+BEGIN_SRC glsl
#version 450
uniform mat4 P;
uniform mat4 V;
uniform mat4 M;

in layout(location = 0) vec4 in_v_positionos;
in layout(location = 1) vec4 in_v_normalos;
in layout(location = 2) vec2 in_v_texCoord;

out layout(location = 0) vec4 out_positioncs;
out layout(location = 1) vec4 out_normalcs;
out layout(location = 2) vec2 out_v_texCoord;

void main() {
  vec4 v_positionos = in_v_positionos;
  vec4 v_normalos = in_v_positionos;
  vec2 v_texCoord = in_v_texCoord;

  gl_Position = P * V * M * v_positionos;
  vec4 positioncs = V * M * v_positionos;
  vec4 normalcs   = inverse(transpose(V * M)) * v_normalos;

  out_positioncs = positioncs;
  out_normalcs = normalcs;
  out_v_texCoord = v_texCoord;
}
#+END_SRC

#+BEGIN_SRC glsl
#version 450

uniform mat4 P;
uniform mat4 V;
uniform mat4 M;
uniform sampler2D myTexture;

struct Light {
  vec4 positionws;
  vec4 color;
};

uniform Light lights[10];

in layout(location = 0) vec4 in_positioncs;
in layout(location = 1) vec4 in_normalcs;
in layout(location = 2) vec2 in_v_texCoord;

out layout(location = 0) vec4 result_color;

void main() {
  vec4 positioncs = in_positioncs;
  vec4 normalcs = in_normalcs;
  vec2 v_texCoord = in_v_texCoord;

  vec4 lighting = vec4(0);

  for(int i = 0; i < 10; ++i) {
    Light light = lights[i];
    vec4 lightpositioncs = V * light.positionws;
    vec4 lightdirectioncs = lightpositioncs - positioncs;
    float light_intensity = dot(lightdirectioncs, normalcs);
    lighting += light_intensity * light.color;
  }

  vec4 textureSample = texture(myTexture, v_texCoord, 0.0);
  result_color = textureSample * lighting;
}
#+END_SRC

 * how do I map symbols/identifiers.

I take out all the _ underscore charactors. They do not have any
meaning in Nim anyway. Then I can use it for my own personal
separation in glsl.


additionally to the shader code, the following OpenGL commands should be
generated:

 * glCompileShader
 * glLinkShader
 * glUninform
 * glAttribute
 * glDraw
 * etc (details you don't wanna know, but I have to fill pages, maybe
   you will get to know them even if you don't want to)

* other example

#+BEGIN_SRC nim
render myVA: (vs, gl) ->

    # face normal test
    let normal = normalize cross(v[0].pos - v[1].pos, v[0].pos - v[2].pos)
    for 1..5:
        for 1..3:
            emit proj * view * model * v.position
        endPrimitive

    # per vertex -> line in vertex normal dir
    var color: Vec3
    var normal: Vec3
    for v in vs:
        for i in 0..1:
            normal = v.normal
            color = if i == 0: vec3(1,0,0) else: vec3(0,0,1)
            emit proj * view * model * (v.position + vec4(v.normal, 0) * i)
        endPrimitive

    result.color = dot(color, normal)


    # per vertex -> line in vertex normal dir
    for v in vs:
        for i in 0..1:
            gl.Position = proj * view * model * (v.position + vec4(v.normal, 0) * i)
            let normal = v.normal
            let color = if i == 0: vec3(1,0,0) else: vec3(0,0,1)
            result.color = dot(color,normal)
            emitVertex()
        endPrimitive(GL_LINE_STRIP)


    # per vertex -> line in vertex normal dir
    for v in vs:

        gl.Position = proj * view * model * (v.position + vec4(v.normal, 0) * i)
        let normal = v.normal
        let color = vec3(1,0,0)
        result.color = dot(color,normal)
        emitVertex()

        gl.Position = proj * view * model * (v.position + vec4(v.normal, 0) * i)
        let normal = v.normal
        let color = vec3(0,0,1)
        result.color = dot(color,normal)
        emitVertex()

        endPrimitive(GL_LINE_STRIP)

#+END_SRC
* mesh type


Designing a flexible concept of a mesh type is not easy.  A generic
mesh type should have the following attributes:

 * Allow arbitrary vertex attributes.  So not only only a subset of
   predefined attribute names like Position Color
   Normal, etc but completely custom attributes with user defined
   identifiers. (any plain old data type).
 * Provide a vertex type (POD) at compile time that will be used for
   semantic checking of the vertex shader.
 * Allow to bind each vertex attribute data to any buffer. This means
   interleaved attributes, non interleaved attributes, different
   buffer positions and completely different buffers.
 * a flexible vertex indices field for arbitrary connectivity.
 * Performance does matter.  So connecting a Mesh data with a shader
   program should not take too long.

TODO: explain vertex indices constraints.

OpenGL has kind of a solution for this concept, the
VertexArrayObject. So in theory everything is specified in the vertex
array object and everything can be set with a single call to
~glBindVertexArray~. But there is a problem. The format that is set
with ~glVertexAttribFormat~ for each vertex attribute index /format/
sets a state in the VertexArrayObject.  For me this is a conflict,
because the program should be responsible for allocating attribute
indices, not a vertex array object.  When the mesh type is defined, it
is not yet known with how many attributes it will later be rendered.
Only the program (the render macro) knows all of the attributes.  I
would like to keep the option open for the program to pull in more
attributes than the ones that are specified by a single mesh.

Just an example for this use case is the following.  Imagine you would
like to render a sphere on each vertex of the rocker arm mesh (this is
done in /OpenFlipper/).  The ideal solution would be to use the vertex
array of the rocker arm mesh and use it as instancing information for
the sphere mesh.  But when both meshes independently gave away
attribute 0, then things might become a bit ugly.  I would not want to
offload the attribute index allocation to the user at all, it clearly
conflicts with my design goal of simplicity.  But there is a solution
that works for my system.  There is a solution for this problem
though.

# TODO maybe reference the design goal simplicity.

I always take the program and a vertex array object as an indivisible
pair, and call that my program.  Then the format and index is again an
attribute of the program.  But then the mesh explicitly does not have
a vertex array object, only a list of buffers and a way to provide
meta information to it.  The actual buffers that are used for
rendering are bound on each frame with ~glVertexArrayVertexBuffers~.
This allows to bind all attribute buffers fast and per frame in a
single call, and the values of the mesh can change at any time without
causing problems.  The only constraint is that all buffers that I bind
this way, need to be bound to a continuous ranged of binding points,
but this is not really a limitation for me (currently for simplicity
attribute binding points and attribute indices are set to be
identical).

void glVertexArrayVertexBuffers(	GLuint vaobj,
 	GLuint first,
 	GLsizei count,
 	const GLuint *buffers,
 	const GLintptr *offsets,
 	const GLsizei *strides);

## the binding index, attribute index indirection

I mentioned earlier that for me binding index, and attribute index is
the same. They are not the same, I just set them to the same integer
value, so that I don't need to think about them anymore as different
indices.  But maybe this is exactly the problem, and if I would do it,
I could use the vertex array object in the mesh.  But I don't think
this is the case I will say why I think this is the case.

I think it would help, when the program would allocate binding points
for all attributes, The Vertex Array Object would provide the
attribute to buffer mapping, and then the render macro can create a
matching for attributes on a vertex array object and the program.  In
theory ~glVertexAttribBinding~ allows for such a mapping, but it sets
the state for the Vertex Array Object, not the program.  Thus I can't
generate the mapping as an initialization of the program.  I did not
find a procedure to set such a mapping in one bulk operation.
* glm port and extensions

In order to be able to have a language that can be translated to both
GLSL for the GPU and C code for the CPU, I wanted to have a mirror
that reflects everything that you can typically do in glsl in a
library for Nim.  The C++ project GLM does already a very good job and
providing the vector math part of glm on the CPU side.  So I looked if
there was something like glm already in Nim.  I found a project called
glm, but this project was very bare bone and written in an almost
unmaintainable style, but I wanted that name. So I fixed that port and
changed almost everything in it. My port is an almost one to one
source port of the original c++ version of glm. Most changes are pure syntax
related.

But since I wanted to program everything in Nim, even the shaders, I
also need to have the GLSL features ported that work on the GPU only.
This is texture sampling.  In order to have texture sampling working,
I need to have all sampler types from GLSL representive in Nim.  For
example sampling from a texture of type ~Texture2D~ will cause a
uniform of type ~sampler2D~ in GLSL.  The whole family of sampler
types is supported though, including /1D/, /3D/, /cube/ and /shadow
samplers/.

Texture sampling itself I implemented with moc procedures. The family
of ~texture~ procedures that is used in GLSL to sample a texture is
implemented in nim just by an empty procedure that instantly throws an
exception.

#+BEGIN_SRC nim
proc texture*(sampler: Texture2D; P: Vec2f; bias: float32 = 0): Vec4f =
  quit("only implemented in shader")
#+END_SRC

So when you call this procedure from the CPU side it will crash your
program, but when you call this procedure from the body of the /shader/,
it will be compiled to the ~texture~ call is very well known to the
glsl compiler.  The nim implementation of ~texture~ will not be
translated to GLSL. It is filtered out as already known by GLSL.

* serialization

I wanted to have a one to one representation of GLSL in Nim.
Semantically I could do it, but I was not able to have binary
compatibility.  The ~vec3~ type in GLSL has an alignment like the type
~vec4~ of 16 bytes, but it is only 12 bytes in size.  This is not
allowed for any type in C, it would break pointer arithmetic (Nim
compiles to C).  GLSL works with this behavior by rounding up the
alignment of every array element and every struct by a multiple of 16
bytes.  But that is not something I have control over in Nim. In order
to work with this alignment differences, I reserialize every Nim
object when I pass it down to GLSL. This way I have control of the
full memory layout, and I can inject all the alignment bytes, where
needed.
